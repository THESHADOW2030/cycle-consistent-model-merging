{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import logging\n",
    "\n",
    "pylogger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from wandb.sdk.wandb_run import Run\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"gladia\", \"cycle-consistent-model-merging\"  # set to your entity and project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(entity, project, positive_tags, negative_tags=None):\n",
    "    filters_pos_tags = {\"$and\": [{\"tags\": {\"$eq\": pos_tag}} for pos_tag in positive_tags]}\n",
    "    filters_neg_tags = {}\n",
    "\n",
    "    print(filters_pos_tags)\n",
    "    filters = {**filters_pos_tags, **filters_neg_tags}\n",
    "    runs = api.runs(entity + \"/\" + project, filters=filters)\n",
    "\n",
    "    print(f\"There are {len(runs)} runs respecting these conditions.\")\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"merge_n_models\", \"8x\", \"cifar100\"]  # 2x, 4x, 8x, cifar100, vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = get_runs(entity, project, positive_tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergers = [\"frank_wolfe\", \"git_rebasin\", \"naive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = {merger: {\"repaired\": {}, \"untouched\": {}} for merger in mergers}\n",
    "print(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_key = \"matching/seed_index\"\n",
    "model_pair_key = \"matching/model_seeds\"\n",
    "\n",
    "merger_key = \"matching/merger/_target_\"\n",
    "\n",
    "gitrebasin_classname = \"ccmm.matching.merger.GitRebasinMerger\"\n",
    "frankwolfe_classname = \"ccmm.matching.merger.FrankWolfeSynchronizedMerger\"\n",
    "naive_classname = \"ccmm.matching.merger.DummyMerger\"\n",
    "\n",
    "model_key = \"model/name\"\n",
    "merger_mapping = {\n",
    "    gitrebasin_classname: \"git_rebasin\",\n",
    "    frankwolfe_classname: \"frank_wolfe\",\n",
    "    naive_classname: \"naive\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in tqdm(runs):\n",
    "    run: Run\n",
    "    cfg = run.config\n",
    "\n",
    "    if len(cfg) == 0:\n",
    "        pylogger.warning(\"Runs are still running, skipping\")\n",
    "        continue\n",
    "\n",
    "    if \"merged\" in cfg[\"core/tags\"]:\n",
    "        repaired_key = \"untouched\"\n",
    "    elif \"repaired\" in cfg[\"core/tags\"]:\n",
    "        repaired_key = \"repaired\"\n",
    "    else:\n",
    "        pylogger.warning(\"Run is neither merged nor repaired, skipping\")\n",
    "        continue\n",
    "\n",
    "    seed = cfg[seed_key]\n",
    "    model_pair = cfg[model_pair_key]\n",
    "\n",
    "    merger_mapped = merger_mapping[cfg[merger_key]]\n",
    "\n",
    "    hist = run.scan_history()\n",
    "\n",
    "    train_acc = run.history(keys=[\"acc/train\"])[\"acc/train\"][0]\n",
    "    test_acc = run.history(keys=[\"acc/test\"])[\"acc/test\"][0]\n",
    "\n",
    "    train_loss = run.history(keys=[\"loss/train\"])[\"loss/train\"][0]\n",
    "    test_loss = run.history(keys=[\"loss/test\"])[\"loss/test\"][0]\n",
    "\n",
    "    exps[merger_mapped][repaired_key] = {\n",
    "        \"train_acc\": train_acc,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for merger_name, merger_repaired_data in exps.items():\n",
    "    for repaired_flag, metrics in merger_repaired_data.items():\n",
    "        if metrics:\n",
    "            record = {\n",
    "                \"merger\": merger_name + \"_\" + repaired_flag,\n",
    "                \"train_acc\": metrics[\"train_acc\"],\n",
    "                \"test_acc\": metrics[\"test_acc\"],\n",
    "                \"train_loss\": metrics[\"train_loss\"],\n",
    "                \"test_loss\": metrics[\"test_loss\"],\n",
    "            }\n",
    "\n",
    "            records.append(record)\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher_to_latex_map = {\n",
    "    \"frank_wolfe_repaired\": r\"\\texttt{Frank-Wolfe}$^\\dagger$\",\n",
    "    \"git_rebasin_repaired\": r\"\\texttt{Git-Rebasin}$^\\dagger$\",\n",
    "    \"naive_untouched\": r\"\\texttt{Naive}\",\n",
    "    \"naive_repaired\": r\"\\texttt{Naive}$^\\dagger$\",\n",
    "    \"frank_wolfe_untouched\": r\"\\texttt{Frank-Wolfe}\",\n",
    "    \"git_rebasin_untouched\": r\"\\texttt{Git-Rebasin}\",\n",
    "}\n",
    "\n",
    "ordering = [\n",
    "    \"naive_untouched\",\n",
    "    \"naive_repaired\",\n",
    "    \"git_rebasin_untouched\",\n",
    "    \"git_rebasin_repaired\",\n",
    "    \"frank_wolfe_untouched\",\n",
    "    \"frank_wolfe_repaired\",\n",
    "]\n",
    "\n",
    "df[\"merger\"] = pd.Categorical(df[\"merger\"], ordering)\n",
    "df.sort_values(by=\"merger\", ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# cmap = \"coolwarm\"\n",
    "cmap = sns.light_palette(\"seagreen\", as_cmap=True)\n",
    "cmap_reverse = sns.light_palette(\"seagreen\", as_cmap=True, reverse=True)\n",
    "# cmap = adjust_cmap_alpha(cmap, alpha=1)\n",
    "# cmap = sns.color_palette(\"vlag\", as_cmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccmm.utils.plot import decimal_to_rgb_color\n",
    "\n",
    "max_loss_value = 6.0\n",
    "\n",
    "header = r\"\"\"\n",
    "\\begin{table}\n",
    "    \\begin{center}\n",
    "        \\begin{tabular}{lccc}\n",
    "        \\toprule\n",
    "        \\textbf{Matcher}        & \\multicolumn{2}{c}{\\textbf{Barrier}}                   \\\\\n",
    "                                & \\textbf{Train}                       & \\textbf{Test}   \\\\\n",
    "        \\midrule\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "body = \"\"\n",
    "\n",
    "for row in df.iterrows():\n",
    "    row = row[1]\n",
    "    merger = row[\"merger\"]\n",
    "\n",
    "    if merger == \"naive_repaired\":\n",
    "        continue\n",
    "\n",
    "    test_acc = row[\"test_acc\"]\n",
    "    train_acc = row[\"train_acc\"]\n",
    "    test_loss = row[\"test_loss\"]\n",
    "    train_loss = row[\"train_loss\"]\n",
    "\n",
    "    test_acc_col = decimal_to_rgb_color(test_acc, cmap)[:3]\n",
    "    train_acc_col = decimal_to_rgb_color(train_acc, cmap)[:3]\n",
    "    test_loss_col = decimal_to_rgb_color(test_loss / max_loss_value, cmap_reverse)[:3]\n",
    "    train_loss_col = decimal_to_rgb_color(train_loss / max_loss_value, cmap_reverse)[:3]\n",
    "\n",
    "    col_and_val = lambda color, value: f\"\\\\cellcolor[rgb]{{{color}}}{value:.2f}\"\n",
    "\n",
    "    body += f\"\"\"\n",
    "                & {matcher_to_latex_map[merger]} &  {col_and_val(train_acc_col, train_acc)} & {col_and_val(test_acc_col, test_acc)} & {col_and_val(train_loss_col, train_loss)} & {col_and_val(test_loss_col, test_loss)} \\\\\\\\\"\"\".replace(\n",
    "        \"(\", \"\"\n",
    "    ).replace(\n",
    "        \")\", \"\"\n",
    "    )\n",
    "\n",
    "footer = r\"\"\"\n",
    "        \\bottomrule\n",
    "        \\end{tabular}\n",
    "    \\end{center}\n",
    "    \\caption{Mean and standard deviation of the test and train loss barrier for each matcher.}\n",
    "    \\label{tab:MLP_loss_barrier}\n",
    "\\end{table}\"\"\"\n",
    "\n",
    "table = header + body + footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
