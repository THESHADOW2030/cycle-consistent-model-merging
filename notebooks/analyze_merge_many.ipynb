{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import math\n",
    "\n",
    "import hydra\n",
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import omegaconf\n",
    "import seaborn as sns\n",
    "import torch  # noqa\n",
    "import wandb\n",
    "from hydra.utils import instantiate\n",
    "from matplotlib import tri\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import LightningModule\n",
    "from scipy.stats import qmc\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from ccmm.matching.utils import perm_indices_to_perm_matrix\n",
    "from ccmm.utils.utils import normalize_unit_norm, project_onto\n",
    "from ccmm.matching.frank_wolfe_sync_matching import frank_wolfe_synchronized_matching\n",
    "from ccmm.matching.utils import perm_matrix_to_perm_indices\n",
    "\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "from nn_core.common.utils import seed_index_everything\n",
    "from nn_core.model_logging import NNLogger\n",
    "from ccmm.utils.utils import fuse_batch_norm_into_conv\n",
    "from torch.utils.data import DataLoader, Subset, SubsetRandomSampler\n",
    "\n",
    "import ccmm  # noqa\n",
    "from ccmm.matching.utils import (\n",
    "    apply_permutation_to_statedict,\n",
    "    get_all_symbols_combinations,\n",
    "    plot_permutation_history_animation,\n",
    "    restore_original_weights,\n",
    ")\n",
    "from ccmm.utils.utils import (\n",
    "    load_model_from_info,\n",
    "    map_model_seed_to_symbol,\n",
    "    save_factored_permutations,\n",
    ")\n",
    "\n",
    "from ccmm.matching.utils import load_permutations\n",
    "\n",
    "from ccmm.utils.utils import vector_to_state_dict\n",
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"font.family\"] = \"serif\"\n",
    "sns.set_context(\"talk\")\n",
    "matplotlib.rcParams[\"text.usetex\"] = True\n",
    "cmap_name = \"coolwarm_r\"\n",
    "\n",
    "logging.getLogger(\"lightning.pytorch\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"torch\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"pytorch_lightning.accelerators.cuda\").setLevel(logging.WARNING)\n",
    "pylogger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def average_models(model_params, reduction_fn, coeffs=None):\n",
    "    if not isinstance(model_params, List):\n",
    "        model_params = list(model_params.values())\n",
    "\n",
    "    if not coeffs:\n",
    "        coeffs = [1] * len(model_params)\n",
    "\n",
    "    return {k: reduction_fn(torch.stack([p[k] for p in model_params])) for k in model_params[0].keys()}\n",
    "\n",
    "\n",
    "def trimmed_mean(tensors, trim_ratio=0.1):\n",
    "    num_values = tensors.size(0)\n",
    "    num_to_trim = int(trim_ratio * num_values)\n",
    "    sorted_tensors = tensors.sort(dim=0).values\n",
    "    trimmed_tensors = sorted_tensors[num_to_trim : num_values - num_to_trim]\n",
    "    return trimmed_tensors.mean(dim=0)\n",
    "\n",
    "\n",
    "def winsorize(tensor, limits=[0.2, 0.8]):\n",
    "    lower, upper = torch.quantile(tensor, torch.tensor(limits).float(), dim=0)\n",
    "    clipped = torch.clamp(tensor, min=lower, max=upper)\n",
    "    return clipped.mean(dim=0)\n",
    "\n",
    "\n",
    "def robust_mean(tensor, threshold=3.5):\n",
    "    median_val = tensor.median(dim=0).values\n",
    "    mad_val = (tensor - median_val).abs().median(dim=0).values\n",
    "    mad_val[mad_val == 0] = 1  # Prevent division by zero\n",
    "    z_score = 0.6745 * (tensor - median_val) / mad_val\n",
    "    mask = (z_score.abs() < threshold).float()  # Create a mask to zero-out outliers\n",
    "    filtered_tensor = tensor * mask  # Apply mask\n",
    "    robust_mean_val = filtered_tensor.sum(dim=0) / mask.sum(dim=0)  # Compute mean only over non-outlier values\n",
    "    return robust_mean_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"merge_n_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"merge_n_models\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_cfg = cfg  # NOQA\n",
    "cfg = cfg.matching\n",
    "\n",
    "seed_index_everything(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 5000\n",
    "num_train_samples = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = instantiate(core_cfg.dataset.test.transform)\n",
    "\n",
    "train_dataset = instantiate(core_cfg.dataset.train, transform=transform)\n",
    "test_dataset = instantiate(core_cfg.dataset.test, transform=transform)\n",
    "\n",
    "train_subset = Subset(train_dataset, list(range(num_train_samples)))\n",
    "train_loader = DataLoader(train_subset, batch_size=5000, num_workers=cfg.num_workers)\n",
    "\n",
    "test_subset = Subset(test_dataset, list(range(num_test_samples)))\n",
    "\n",
    "test_loader = DataLoader(test_subset, batch_size=1000, num_workers=cfg.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = instantiate(cfg.trainer, enable_progress_bar=False, enable_model_summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccmm.utils.utils import load_model_from_artifact\n",
    "\n",
    "run = wandb.init(project=core_cfg.core.project_name, entity=core_cfg.core.entity, job_type=\"matching\")\n",
    "\n",
    "# {a: 1, b: 2, c: 3, ..}\n",
    "symbols_to_seed: Dict[int, str] = {map_model_seed_to_symbol(seed): seed for seed in cfg.model_seeds}\n",
    "\n",
    "artifact_path = (\n",
    "    lambda seed: f\"{core_cfg.core.entity}/{core_cfg.core.project_name}/{core_cfg.dataset.name}_{core_cfg.model.model_identifier}_{seed}:v0\"\n",
    ")\n",
    "\n",
    "# {a: model_a, b: model_b, c: model_c, ..}\n",
    "models: Dict[str, LightningModule] = {\n",
    "    map_model_seed_to_symbol(seed): load_model_from_artifact(run, artifact_path(seed)) for seed in cfg.model_seeds\n",
    "}\n",
    "\n",
    "num_models = len(models)\n",
    "\n",
    "pylogger.info(f\"Using {num_models} models with architecture {core_cfg.model.model_identifier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always permute the model having larger character order, i.e. c -> b, b -> a and so on ...\n",
    "symbols = set(symbols_to_seed.keys())\n",
    "symbols = symbols.difference({\"o\"})  # \"o\" is the model trained over all the dataset\n",
    "\n",
    "sorted_symbols = sorted(symbols, reverse=False)\n",
    "\n",
    "# (a, b), (a, c), (b, c), ...\n",
    "all_combinations = get_all_symbols_combinations(symbols)\n",
    "# combinations of the form (a, b), (a, c), (b, c), .. and not (b, a), (c, a) etc\n",
    "canonical_combinations = [(source, target) for (source, target) in all_combinations if source < target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylogger.info(f\"Matching the following model pairs: {canonical_combinations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load permutation specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_spec_builder = instantiate(core_cfg.model.permutation_spec_builder)\n",
    "permutation_spec = permutation_spec_builder.create_permutation()\n",
    "\n",
    "ref_model = list(models.values())[0]\n",
    "assert set(permutation_spec.layer_and_axes_to_perm.keys()) == set(ref_model.model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_merger = instantiate(cfg.merger, permutation_spec=permutation_spec)\n",
    "\n",
    "pylogger.info(f\"Merger: {model_merger.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 200\n",
    "initialization_method = \"identity\"\n",
    "keep_soft_perms = True\n",
    "\n",
    "symbols = list(models.keys())\n",
    "\n",
    "merged_model = copy.deepcopy(models[symbols[0]])\n",
    "\n",
    "perm_indices, opt_infos = frank_wolfe_synchronized_matching(\n",
    "    models=models,\n",
    "    perm_spec=permutation_spec,\n",
    "    symbols=symbols,\n",
    "    combinations=canonical_combinations,\n",
    "    max_iter=max_iter,\n",
    "    initialization_method=initialization_method,\n",
    "    keep_soft_perms=keep_soft_perms,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perm_symbols = list(perm_indices['a'].keys())\n",
    "# # perm_symbols = ['P_bg0', 'P_blockgroup3.block2_inner']\n",
    "# k = 0\n",
    "# K = 5\n",
    "# for perm_symb in perm_symbols:\n",
    "#     perms = {symb: [perm[symb][perm_symb] for perm in opt_infos['perm_history'][k:K]] for symb in symbols }\n",
    "\n",
    "#     fig, ax = plt.subplots(5, K-k, figsize=(20, 20))\n",
    "\n",
    "#     for i in range(K-k):\n",
    "#         for j, symb in enumerate(symbols):\n",
    "#             ax[j, i].imshow(perms[symb][i].cpu(), cmap='gray')\n",
    "#             ax[j, i].axis('off')\n",
    "#             ax[j, i].set_title(symb)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_symbols = list(perm_indices[\"a\"].keys())\n",
    "print(perm_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(opt_infos[\"obj_values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([step_size for ind, step_size in enumerate(opt_infos[\"step_sizes\"]) if ind % 2 == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([step_size for ind, step_size in enumerate(opt_infos[\"step_sizes\"]) if ind % 2 == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccmm.matching.weight_matching import solve_linear_assignment_problem\n",
    "\n",
    "hard_perms = {\n",
    "    symb: {p: solve_linear_assignment_problem(perm) for p, perm in perm_indices[symb].items()} for symb in symbols\n",
    "}\n",
    "\n",
    "soft_perms = copy.deepcopy(perm_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perms = False\n",
    "if plot_perms:\n",
    "    perm_symbols = list(perm_indices[\"a\"].keys())\n",
    "\n",
    "    for perm_symbol in perm_symbols:\n",
    "        fig, axs = plt.subplots(2, len(symbols), figsize=(40, 20))\n",
    "        fig.suptitle(f\"Permutation: {perm_symbol}\", fontsize=16)\n",
    "        for i, symbol in enumerate(symbols):\n",
    "\n",
    "            ax0 = axs[0][i]\n",
    "            ax0.set_title(symbol)\n",
    "            ax0.imshow(soft_perms[symbol][perm_symbol].cpu(), cmap=cmap_name)\n",
    "            ax0.colorbar = plt.colorbar(\n",
    "                matplotlib.cm.ScalarMappable(norm=colors.Normalize(vmin=0, vmax=1), cmap=cmap_name), ax=ax0\n",
    "            )\n",
    "\n",
    "            ax1 = axs[1][i]\n",
    "            ax1.set_title(symbol)\n",
    "            ax1.imshow(perm_indices_to_perm_matrix(hard_perms[symbol][perm_symbol]), cmap=cmap_name)\n",
    "            ax1.colorbar = plt.colorbar(\n",
    "                matplotlib.cm.ScalarMappable(norm=colors.Normalize(vmin=0, vmax=1), cmap=cmap_name), ax=ax1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_name = \"P_blockgroup2.block3_inner\"\n",
    "nonzero_idxs = (soft_perms[\"a\"][perm_name] > 0) & (soft_perms[\"a\"][perm_name] < 1)\n",
    "\n",
    "soft_perms[\"a\"][perm_name][nonzero_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_permuted_to_univ(perms, models, symbols, keep_soft_perms=False):\n",
    "    models_permuted_to_universe = {symbol: copy.deepcopy(model) for symbol, model in models.items()}\n",
    "\n",
    "    for symbol in symbols:\n",
    "        perms_to_apply = {}\n",
    "\n",
    "        for perm_name in perms[symbol].keys():\n",
    "            perm = perms[symbol][perm_name]\n",
    "\n",
    "            if keep_soft_perms:\n",
    "                perm = perm.T\n",
    "                perm_to_apply = perm\n",
    "            else:\n",
    "                perm = perm_indices_to_perm_matrix(perm).T\n",
    "                perm_to_apply = perm_matrix_to_perm_indices(perm)\n",
    "\n",
    "            perms_to_apply[perm_name] = perm_to_apply\n",
    "\n",
    "        updated_params = apply_permutation_to_statedict(\n",
    "            permutation_spec, perms_to_apply, models[symbol].model.state_dict()\n",
    "        )\n",
    "        models_permuted_to_universe[symbol].model.load_state_dict(updated_params)\n",
    "\n",
    "    return models_permuted_to_universe\n",
    "\n",
    "\n",
    "models_permuted_to_universe = get_models_permuted_to_univ(soft_perms, models, symbols, keep_soft_perms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccmm.matching.utils import unfactor_permutations\n",
    "\n",
    "models_permuted_pairwise = {\n",
    "    symbol: {other_symb: None for other_symb in set(symbols).difference(symbol)} for symbol in symbols\n",
    "}\n",
    "pairwise_permutations = unfactor_permutations(hard_perms)\n",
    "\n",
    "for fixed, permutee in all_combinations:\n",
    "    ref_model = copy.deepcopy(models[\"a\"])\n",
    "\n",
    "    permuted_params = apply_permutation_to_statedict(\n",
    "        permutation_spec, pairwise_permutations[fixed][permutee], models[permutee].model.state_dict()\n",
    "    )\n",
    "\n",
    "    ref_model.model.load_state_dict(permuted_params)\n",
    "    models_permuted_pairwise[fixed][permutee] = ref_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {symb: model.to(\"cpu\") for symb, model in models.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if they are orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_models = {symbol: torch.nn.utils.parameters_to_vector(model.parameters()) for symbol, model in models.items()}\n",
    "flat_models_permuted_to_universe = {\n",
    "    symbol: torch.nn.utils.parameters_to_vector(model.parameters())\n",
    "    for symbol, model in models_permuted_to_universe.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cosine_similarities(models):\n",
    "    # matrix of the cosine products\n",
    "    cosine_matrix = np.zeros((len(models), len(models)))\n",
    "\n",
    "    for i, (symbol_i, model_i) in enumerate(models.items()):\n",
    "        for j, (symbol_j, model_j) in enumerate(models.items()):\n",
    "            cosine_matrix[i, j] = (model_i @ model_j) / (torch.norm(model_i) * torch.norm(model_j))\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(cosine_matrix, annot=True, cmap=\"viridis\")\n",
    "    plt.title(\"Cosine Similarity Matrix\")\n",
    "    plt.ylabel(\"Model Symbol\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cosine_similarities(flat_models)\n",
    "plot_cosine_similarities(flat_models_permuted_to_universe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try fancy averaging functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "model_params = [model.model.state_dict() for model in models_permuted_to_universe.values()]\n",
    "\n",
    "red_fns = {\"mean\": partial(torch.mean, dim=0), \"trimmed\": trimmed_mean, \"winsor\": winsorize, \"filter\": robust_mean}\n",
    "merged_params = average_models(model_params, reduction_fn=red_fns[\"mean\"])\n",
    "merged_model.model.load_state_dict(merged_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = test_loader\n",
    "trainer.test(merged_model, loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccmm.matching.repair import repair_model\n",
    "\n",
    "repaired_model = repair_model(merged_model, models_permuted_to_universe, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(repaired_model, loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_permuted_to_universe = {symb: model.to(\"cpu\") for symb, model in models_permuted_to_universe.items()}\n",
    "fishers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccmm.matching.fisher_merging import compute_fisher_for_model\n",
    "\n",
    "num_fisher_samples = 2000\n",
    "fisher_train_subset = Subset(train_dataset, list(range(num_fisher_samples)))\n",
    "\n",
    "fisher_train_loader = DataLoader(fisher_train_subset, batch_size=8)\n",
    "\n",
    "num_classes = core_cfg.dataset.num_classes\n",
    "\n",
    "fishers = {\n",
    "    symbol: compute_fisher_for_model(model.model, fisher_train_loader, num_classes)\n",
    "    for symbol, model in models_permuted_to_universe.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models_permuted_to_universe.values():\n",
    "    model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = copy.deepcopy(models[\"a\"])\n",
    "for param_name, param in merged_model.model.named_parameters():\n",
    "    param.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = copy.deepcopy(models_permuted_to_universe[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol, model in models_permuted_to_universe.items():\n",
    "    for param_name, param in model.model.named_parameters():\n",
    "\n",
    "        to_add = torch.zeros_like(param.data)\n",
    "        target_param = target_model.model.state_dict()[param_name].data\n",
    "\n",
    "        fish_coeff = fishers[symbol][param_name]\n",
    "\n",
    "        all_fishers = torch.stack([fishers[symb][param_name] for symb in symbols])\n",
    "        fish_coeff = fish_coeff / all_fishers.sum(dim=0)\n",
    "\n",
    "        tol = 1e-12\n",
    "\n",
    "        num_small_fish = (fish_coeff < tol).sum()\n",
    "        ratio_small_fish = num_small_fish / fish_coeff.numel()\n",
    "\n",
    "        pylogger.info(f\"Number of small fish: {num_small_fish}, ratio: {ratio_small_fish}\")\n",
    "        pylogger.info(f\"Average fisher: {fish_coeff.mean()}\")\n",
    "\n",
    "        to_add[fish_coeff < tol] = target_param[fish_coeff < tol] * (1 / num_models)\n",
    "\n",
    "        to_add[fish_coeff >= tol] = param.data[fish_coeff >= tol] * (1 / num_models) * fish_coeff[fish_coeff >= tol]\n",
    "\n",
    "        merged_model.model.state_dict()[param_name].add_(to_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(merged_model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(target_model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repaired_model = repair_model(merged_model, models_permuted_to_universe, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(repaired_model, loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using one of the models as reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {symbol: {\"vanilla\": None, \"merged\": None} for symbol in symbols}\n",
    "\n",
    "for symbol in symbols:\n",
    "\n",
    "    mapped_models = {\n",
    "        other_symb: models_permuted_pairwise[symbol][other_symb]\n",
    "        for other_symb, model in models.items()\n",
    "        if other_symb != symbol\n",
    "    }\n",
    "    mapped_params = {symb: model.model.state_dict() for symb, model in mapped_models.items()}\n",
    "\n",
    "    merged_model = copy.deepcopy(models[symbol])\n",
    "\n",
    "    mean_model = average_models(mapped_params, reduction_fn=red_fns[\"mean\"])\n",
    "\n",
    "    merged_model.model.load_state_dict(mean_model)\n",
    "\n",
    "    vanilla_res = trainer.test(merged_model, loader)[0]\n",
    "\n",
    "    repaired_model = repair_model(merged_model, mapped_models, train_loader)\n",
    "\n",
    "    repair_res = trainer.test(repaired_model, loader)[0]\n",
    "\n",
    "    results[symbol][\"vanilla\"] = vanilla_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_subsets = {symbol: set(symbols).difference(symbol) for symbol in symbols}\n",
    "\n",
    "merged_model = copy.deepcopy(models[symbols[0]])\n",
    "\n",
    "results = {}\n",
    "merged_models = {}\n",
    "\n",
    "for symbol_subset in symbol_subsets.values():\n",
    "\n",
    "    combinations = get_all_symbols_combinations(symbol_subset)\n",
    "    canonical_combinations = [(source, target) for (source, target) in combinations if source < target]\n",
    "    model_subset = {symb: models[symb] for symb in symbol_subset}\n",
    "\n",
    "    perm_indices, _ = frank_wolfe_synchronized_matching(\n",
    "        models=model_subset,\n",
    "        perm_spec=permutation_spec,\n",
    "        symbols=list(symbol_subset),\n",
    "        combinations=canonical_combinations,\n",
    "        max_iter=max_iter,\n",
    "        initialization_method=initialization_method,\n",
    "        keep_soft_perms=keep_soft_perms,\n",
    "    )\n",
    "\n",
    "    pylogger.info(f\"Symbol subset: {symbol_subset}\")\n",
    "\n",
    "    models_to_univ_subset = get_models_permuted_to_univ(model_subset, symbol_subset, keep_soft_perms)\n",
    "\n",
    "    model_params = [model.model.state_dict() for model in models_to_univ_subset.values()]\n",
    "\n",
    "    merged_params = average_models(model_params, reduction_fn=red_fns[\"mean\"])\n",
    "    merged_model.model.load_state_dict(merged_params)\n",
    "\n",
    "    merged_results = trainer.test(merged_model, loader)[0]\n",
    "\n",
    "    repaired_model = repair_model(merged_model, models_to_univ_subset, train_loader)\n",
    "\n",
    "    repair_results = trainer.test(repaired_model, loader)[0]\n",
    "\n",
    "    results[tuple(symbol_subset)] = {\"merged\": merged_results, \"repaired\": repair_results}\n",
    "    merged_models[tuple(symbol_subset)] = {\"merged\": merged_model, \"repaired\": repaired_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try subsets without re-aligning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = get_all_symbols_combinations(symbols)\n",
    "canonical_combinations = [(source, target) for (source, target) in all_combinations if source < target]\n",
    "\n",
    "perm_indices, _ = frank_wolfe_synchronized_matching(\n",
    "    models=models,\n",
    "    perm_spec=permutation_spec,\n",
    "    symbols=symbols,\n",
    "    combinations=canonical_combinations,\n",
    "    max_iter=max_iter,\n",
    "    initialization_method=initialization_method,\n",
    "    keep_soft_perms=keep_soft_perms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = copy.deepcopy(models[symbols[0]])\n",
    "models_permuted_to_universe = get_models_permuted_to_univ(models, symbols, keep_soft_perms)\n",
    "\n",
    "results_norealign = {}\n",
    "merged_models_norealign = {}\n",
    "\n",
    "for symbol_subset in symbol_subsets.values():\n",
    "    pylogger.info(f\"Symbol subset: {symbol_subset}\")\n",
    "\n",
    "    models_to_univ_subset = {symb: models_permuted_to_universe[symb] for symb in symbol_subset}\n",
    "\n",
    "    model_params = [model.model.state_dict() for model in models_to_univ_subset.values()]\n",
    "\n",
    "    merged_params = average_models(model_params, reduction_fn=red_fns[\"mean\"])\n",
    "    merged_model.model.load_state_dict(merged_params)\n",
    "\n",
    "    merged_results = trainer.test(merged_model, loader)[0]\n",
    "\n",
    "    repaired_model = repair_model(merged_model, models_to_univ_subset, train_loader)\n",
    "\n",
    "    repair_results = trainer.test(repaired_model, loader)[0]\n",
    "\n",
    "    results_norealign[tuple(symbol_subset)] = {\"merged\": merged_results, \"repaired\": repair_results}\n",
    "    merged_models_norealign[tuple(symbol_subset)] = {\"merged\": merged_model, \"repaired\": repaired_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze models as vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_models_permuted_pairwise = {\n",
    "    symbol: {\n",
    "        other_symb: torch.nn.utils.parameters_to_vector(model.parameters()) for other_symb, model in models.items()\n",
    "    }\n",
    "    for symbol, models in models_permuted_pairwise.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(model_a, model_b, lamb):\n",
    "    return (1 - lamb) * model_a + lamb * model_b\n",
    "\n",
    "\n",
    "def get_interp_curve(lambdas, model_a, model_b, ref_model, test_loader):\n",
    "    interp_losses = []\n",
    "    interp_accs = []\n",
    "\n",
    "    for lamb in lambdas:\n",
    "        interp_params = linear_interpolation(model_a=model_a, model_b=model_b, lamb=lamb)\n",
    "\n",
    "        interp_params = vector_to_state_dict(interp_params, ref_model.model)\n",
    "\n",
    "        ref_model.model.load_state_dict(interp_params)\n",
    "        results = trainer.test(ref_model, test_loader, verbose=False)\n",
    "\n",
    "        interp_losses.append(results[0][f\"loss/test\"])\n",
    "        interp_accs.append(results[0][f\"acc/test\"])\n",
    "\n",
    "    return interp_losses, interp_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average in the universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = copy.deepcopy(models[\"a\"])\n",
    "\n",
    "vec = torch.nn.utils.parameters_to_vector(merged_model.parameters())\n",
    "\n",
    "vec = torch.stack([model for model in flat_models_permuted_to_universe.values()]).mean(dim=0)\n",
    "\n",
    "torch.nn.utils.vector_to_parameters(vec, merged_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot LMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lmc(values, lambdas, labels, axis=None):\n",
    "\n",
    "    num_curves = len(values)\n",
    "    transparencies = np.linspace(0.5, 1, num_curves)\n",
    "    linewidths = np.linspace(2.0, 4.0, num_curves)\n",
    "\n",
    "    for i, (val, label) in enumerate(zip(values, labels)):\n",
    "        if axis is None:\n",
    "            axis = plt\n",
    "\n",
    "        axis.plot(lambdas, val, label=label, alpha=transparencies[i], linewidth=linewidths[i])\n",
    "\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_perm_to_a = models_permuted_pairwise[\"a\"][\"b\"]\n",
    "lambdas = np.linspace(0, 1, 3)\n",
    "\n",
    "from ccmm.utils.utils import get_interpolated_loss_acc_curves\n",
    "\n",
    "loss, acc = get_interpolated_loss_acc_curves(\n",
    "    model_a=models[\"a\"],\n",
    "    model_b=p_perm_to_a,\n",
    "    lambdas=lambdas,\n",
    "    ref_model=ref_model,\n",
    "    trainer=trainer,\n",
    "    loader=test_dataloaders[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [loss]\n",
    "labels = [\"Loss\"]\n",
    "plot_lmc(values, lambdas, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [acc]\n",
    "labels = [\"Acc\"]\n",
    "plot_lmc(values, lambdas, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
