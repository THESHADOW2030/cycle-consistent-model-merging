{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import logging\n",
    "\n",
    "pylogger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from wandb.sdk.wandb_run import Run\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"gladia\", \"cycle-consistent-model-merging\"  # set to your entity and project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(entity, project, positive_tags, negative_tags=None):\n",
    "\n",
    "    filters_pos_tags = {\"$and\": [{\"tags\": {\"$eq\": pos_tag}} for pos_tag in positive_tags]}\n",
    "    filters_neg_tags = {}\n",
    "\n",
    "    print(filters_pos_tags)\n",
    "    filters = {**filters_pos_tags, **filters_neg_tags}\n",
    "    runs = api.runs(entity + \"/\" + project, filters=filters)\n",
    "\n",
    "    print(f\"There are {len(runs)} runs respecting these conditions.\")\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"scaling\", \"4x\"]  # 4x, mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = get_runs(entity, project, positive_tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_key = \"matching/seed_index\"\n",
    "model_pair_key = \"matching/model_seeds\"\n",
    "\n",
    "merger_key = \"matching/merger/_target_\"\n",
    "\n",
    "gitrebasin_classname = \"ccmm.matching.merger.GitRebasinMerger\"\n",
    "frankwolfe_classname = \"ccmm.matching.merger.FrankWolfeSynchronizedMerger\"\n",
    "naive_classname = \"ccmm.matching.merger.DummyMerger\"\n",
    "\n",
    "model_key = \"model/name\"\n",
    "merger_mapping = {\n",
    "    gitrebasin_classname: \"git_rebasin\",\n",
    "    frankwolfe_classname: \"frank_wolfe\",\n",
    "    naive_classname: \"naive\",\n",
    "}\n",
    "mergers = [\"git_rebasin\", \"frank_wolfe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_models = 10\n",
    "exps = {merger: [{} for i in range(max_num_models + 1)] for merger in mergers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in tqdm(runs):\n",
    "    run: Run\n",
    "    cfg = run.config\n",
    "\n",
    "    if len(cfg) == 0:\n",
    "        pylogger.warning(\"Runs are still running, skipping\")\n",
    "        continue\n",
    "\n",
    "    num_models = len(cfg[\"matching/model_seeds\"])\n",
    "\n",
    "    model_name = cfg[model_key]\n",
    "    merger = cfg[merger_key]\n",
    "\n",
    "    hist = run.scan_history()\n",
    "    merger_mapped = merger_mapping[cfg[merger_key]]\n",
    "\n",
    "    train_acc = run.history(keys=[\"acc/train\"])[\"acc/train\"][0]\n",
    "    test_acc = run.history(keys=[\"acc/test\"])[\"acc/test\"][0]\n",
    "\n",
    "    train_loss = run.history(keys=[\"loss/train\"])[\"loss/train\"][0]\n",
    "    test_loss = run.history(keys=[\"loss/test\"])[\"loss/test\"][0]\n",
    "\n",
    "    exps[merger_mapped][num_models] = {\n",
    "        \"train_acc\": train_acc,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test accuracies\n",
    "records = []\n",
    "\n",
    "for merger_name, merger_repaired_data in exps.items():\n",
    "    record = {\n",
    "        \"merger\": merger_name,\n",
    "        \"num_models\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_acc\": [],\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(exps)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_metric = {\n",
    "    \"acc\": \"Accuracy\",\n",
    "    \"loss\": \"Loss\",\n",
    "}\n",
    "\n",
    "\n",
    "for metric in [\"acc\", \"loss\"]:\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for merger in mergers:\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[f\"train_{metric}\"], mode=\"lines+markers\", name=\"Train\"))\n",
    "        fig.add_trace(go.Scatter(x=df.index, y=df[f\"test_{metric}\"], mode=\"lines+markers\", name=\"Test\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{pretty_metric[metric]} vs Number of Models\",\n",
    "        xaxis_title=\"Number of Models\",\n",
    "        yaxis_title=f\"{pretty_metric[metric]}\",\n",
    "        width=500,  # Adjust based on your column width in pixels\n",
    "        height=400,  # Adjust for desired aspect ratio\n",
    "        font=dict(size=10),  # Adjust font size for readability\n",
    "        margin=dict(l=50, r=50, t=50, b=50),\n",
    "    ),  # Adjust margins to optimize space)# let the axis start from 2\n",
    "    fig.update_xaxes(range=[1.7, max_num_models + 0.3])\n",
    "\n",
    "    fig.show()\n",
    "    pio.write_image(fig, f\"figures/scaling_exp_{metric}_{model_name}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
