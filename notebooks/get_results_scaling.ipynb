{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import logging\n",
    "\n",
    "pylogger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from wandb.sdk.wandb_run import Run\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "api = wandb.Api()\n",
    "entity, project = \"gladia\", \"cycle-consistent-model-merging\"  # set to your entity and project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_runs(entity, project, positive_tags, negative_tags=None):\n",
    "    filters_pos_tags = {\"$and\": [{\"tags\": {\"$eq\": pos_tag}} for pos_tag in positive_tags]}\n",
    "    filters_neg_tags = {}\n",
    "\n",
    "    print(filters_pos_tags)\n",
    "    filters = {**filters_pos_tags, **filters_neg_tags}\n",
    "    runs = api.runs(entity + \"/\" + project, filters=filters)\n",
    "\n",
    "    print(f\"There are {len(runs)} runs respecting these conditions.\")\n",
    "    return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [\"scaling\", \"4x\"]  # 4x, mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = get_runs(entity, project, positive_tags=tags)  # negative_tags=[\"git_rebasin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_key = \"matching/seed_index\"\n",
    "model_pair_key = \"matching/model_seeds\"\n",
    "\n",
    "merger_key = \"matching/merger/_target_\"\n",
    "\n",
    "gitrebasin_classname = \"ccmm.matching.merger.GitRebasinMerger\"\n",
    "frankwolfe_classname = \"ccmm.matching.merger.FrankWolfeSynchronizedMerger\"\n",
    "naive_classname = \"ccmm.matching.merger.DummyMerger\"\n",
    "\n",
    "model_key = \"model/name\"\n",
    "merger_mapping = {\n",
    "    gitrebasin_classname: \"git_rebasin\",\n",
    "    frankwolfe_classname: \"frank_wolfe\",\n",
    "    naive_classname: \"naive\",\n",
    "}\n",
    "mergers = [\"git_rebasin\", \"frank_wolfe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_models = 11\n",
    "exps = {merger: [{} for i in range(max_num_models + 1)] for merger in mergers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in tqdm(runs):\n",
    "    run: Run\n",
    "    cfg = run.config\n",
    "\n",
    "    if len(cfg) == 0:\n",
    "        pylogger.warning(\"Runs are still running, skipping\")\n",
    "        continue\n",
    "\n",
    "    num_models = len(cfg[\"matching/model_seeds\"])\n",
    "\n",
    "    model_name = cfg[model_key]\n",
    "    merger = cfg[merger_key]\n",
    "\n",
    "    hist = run.scan_history()\n",
    "    merger_mapped = merger_mapping[cfg[merger_key]]\n",
    "\n",
    "    train_acc = run.history(keys=[\"acc/train\"])[\"acc/train\"][0]\n",
    "    test_acc = run.history(keys=[\"acc/test\"])[\"acc/test\"][0]\n",
    "\n",
    "    train_loss = run.history(keys=[\"loss/train\"])[\"loss/train\"][0]\n",
    "    test_loss = run.history(keys=[\"loss/test\"])[\"loss/test\"][0]\n",
    "\n",
    "    exps[merger_mapped][num_models] = {\n",
    "        \"train_acc\": train_acc,\n",
    "        \"test_acc\": test_acc,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train and test accuracies\n",
    "records = []\n",
    "\n",
    "# exps has structure {merger_name: [ {'acc:' acc(1, 2), 'loss': loss(1,2)}, {'acc': acc(1, 2,3), 'loss': loss(1, 2,3)}, ...], ...}]}\n",
    "# where acc(1, 2, 3) is the accuracy of the model merged from seeds 1, 2, 3\n",
    "for merger_name, merger_data in exps.items():\n",
    "    for results in merger_data:\n",
    "        if len(results) == 0:\n",
    "            continue\n",
    "\n",
    "        record = {\n",
    "            \"merger\": merger_name,\n",
    "            \"train_acc\": results[\"train_acc\"],\n",
    "            \"test_acc\": results[\"test_acc\"],\n",
    "            \"train_loss\": results[\"train_loss\"],\n",
    "            \"test_loss\": results[\"test_loss\"],\n",
    "        }\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_dfs = {merger: df[df[\"merger\"] == merger] for merger in mergers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merger_df in merger_dfs.values():\n",
    "    merger_df.index = range(2, len(merger_df) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "pretty_metric = {\n",
    "    \"acc\": \"Accuracy\",\n",
    "    \"loss\": \"Loss\",\n",
    "}\n",
    "\n",
    "color_map = {\n",
    "    \"git_rebasin\": {\n",
    "        \"train\": \"blue\",\n",
    "        \"test\": \"blue\",\n",
    "    },\n",
    "    \"frank_wolfe\": {\n",
    "        \"train\": \"red\",\n",
    "        \"test\": \"red\",\n",
    "    },\n",
    "}\n",
    "\n",
    "dash_map = {\n",
    "    \"git_rebasin\": {\n",
    "        \"train\": \"solid\",\n",
    "        \"test\": \"dot\",\n",
    "    },\n",
    "    \"frank_wolfe\": {\n",
    "        \"train\": \"solid\",\n",
    "        \"test\": \"dot\",\n",
    "    },\n",
    "}\n",
    "\n",
    "merger_map = {\n",
    "    \"git_rebasin\": r\"$\\text{MergeMany}\",\n",
    "    \"frank_wolfe\": \"$C^2M^3\",\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[r\"$\\text{Accuracy}$\", r\"$\\text{Loss}$\"])\n",
    "\n",
    "for merger_name, merger_df in merger_dfs.items():\n",
    "    for metric_ind, metric in enumerate([\"acc\", \"loss\"]):\n",
    "        show_legend = True if metric_ind == 0 else False\n",
    "\n",
    "        train_label = merger_map[merger_name] + r\"\\\\ (\\text{train})$\"\n",
    "        test_label = merger_map[merger_name] + r\"\\\\ (\\text{test})$\"\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=merger_df.index,\n",
    "                y=merger_df[f\"train_{metric}\"],\n",
    "                mode=\"lines\",\n",
    "                name=train_label,\n",
    "                showlegend=show_legend,\n",
    "                line=dict(color=color_map[merger_name][\"train\"], dash=dash_map[merger_name][\"train\"], width=1),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=metric_ind + 1,\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=merger_df.index,\n",
    "                y=merger_df[f\"test_{metric}\"],\n",
    "                mode=\"lines\",\n",
    "                name=test_label,\n",
    "                showlegend=show_legend,\n",
    "                line=dict(color=color_map[merger_name][\"test\"], dash=dash_map[merger_name][\"test\"], width=1),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=metric_ind + 1,\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    width=500,\n",
    "    height=400,\n",
    "    font=dict(size=10),\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    "),\n",
    "fig.update_xaxes(range=[1.7, max_num_models + 0.3])\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(x=0.8, y=-0.0, bgcolor=\"rgba(255,255,255,0.)\"),\n",
    "    width=600,\n",
    "    height=300,\n",
    "    font=dict(size=22),\n",
    "    margin=dict(l=50, r=50, t=50, b=50),\n",
    ")\n",
    "fig.update_annotations(font_size=25)\n",
    "\n",
    "# Update layout for the legend\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # Horizontal orientation\n",
    "        x=0.5,  # Center the legend on the x-axis\n",
    "        y=-0.2,  # Position the legend below the plot\n",
    "        xanchor=\"center\",  # Anchor the center of the legend at x\n",
    "        yanchor=\"top\",  # Anchor the top of the legend at y\n",
    "    ),\n",
    "    # Adjust the bottom margin to ensure the legend is visible and not cut off\n",
    "    margin=dict(b=100),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "pio.write_image(fig, f\"figures/scaling_exp_{model_name}.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
