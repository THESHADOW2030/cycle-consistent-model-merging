{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTu71N5FwVnb"
   },
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMDsjCENv7mW",
    "outputId": "09799337-674a-4240-cb6e-d66f9dea19ce"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCXtENV8xXJx"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5t4q01KIxYuJ"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, Mapping, Optional, Sequence, Tuple, Union\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSmkCPy0xOc2"
   },
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PyJIw7nxPzp",
    "outputId": "b0f3ee5b-d810-4a3f-b389-b3a002e7eb3e"
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vM0UnnNwbGE"
   },
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0CtAZ6dvNHc"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input=28 * 28, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.input = input\n",
    "        self.layer0 = nn.Linear(input, 512)\n",
    "        self.layer1 = nn.Linear(512, 512)\n",
    "        self.layer2 = nn.Linear(512, 512)\n",
    "        self.layer3 = nn.Linear(512, 256)\n",
    "        self.layer4 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input)\n",
    "\n",
    "        h0 = nn.functional.relu(self.layer0(x))\n",
    "\n",
    "        h1 = nn.functional.relu(self.layer1(h0))\n",
    "\n",
    "        h2 = nn.functional.relu(self.layer2(h1))\n",
    "\n",
    "        h3 = nn.functional.relu(self.layer3(h2))\n",
    "\n",
    "        h4 = self.layer4(h3)\n",
    "\n",
    "        embeddings = [h0, h1, h2, h3, h4]\n",
    "\n",
    "        return nn.functional.log_softmax(h4, dim=-1), embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD7fHC05v2UA"
   },
   "outputs": [],
   "source": [
    "class MyLightningModule(pl.LightningModule):\n",
    "    def __init__(self, model, num_classes: int = None, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        metric = torchmetrics.Accuracy(task=\"multiclass\", top_k=1, num_classes=num_classes)\n",
    "        self.train_accuracy = metric.clone()\n",
    "        self.val_accuracy = metric.clone()\n",
    "        self.test_accuracy = metric.clone()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Method for the forward pass.\n",
    "\n",
    "        'training_step', 'validation_step' and 'test_step' should call\n",
    "        this method in order to compute the output predictions and the loss.\n",
    "\n",
    "        Returns:\n",
    "            output_dict: forward output containing the predictions (output logits ecc...) and the loss if any.\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def unwrap_batch(self, batch):\n",
    "        if isinstance(batch, Dict):\n",
    "            x, y = batch[\"x\"], batch[\"y\"]\n",
    "        else:\n",
    "            x, y = batch\n",
    "        return x, y\n",
    "\n",
    "    def step(self, x, y) -> Mapping[str, Any]:\n",
    "\n",
    "        output = self(x)\n",
    "        if isinstance(output, tuple):\n",
    "            logits, embeddings = output\n",
    "        else:\n",
    "            logits = output\n",
    "            embeddings = None\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        return {\"logits\": logits.detach(), \"loss\": loss, \"embeddings\": embeddings}\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int) -> Mapping[str, Any]:\n",
    "        x, y = self.unwrap_batch(batch)\n",
    "\n",
    "        step_out = self.step(x, y)\n",
    "        self.log_dict(\n",
    "            {\"loss/train\": step_out[\"loss\"].cpu().detach()},\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        self.train_accuracy(torch.softmax(step_out[\"logits\"], dim=-1), y)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"acc/train\": self.train_accuracy,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "        )\n",
    "\n",
    "        return step_out\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int) -> Mapping[str, Any]:\n",
    "        x, y = self.unwrap_batch(batch)\n",
    "\n",
    "        step_out = self.step(x, y)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"loss/val\": step_out[\"loss\"].cpu().detach()},\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "        )\n",
    "\n",
    "        self.val_accuracy(torch.softmax(step_out[\"logits\"], dim=-1), y)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"acc/val\": self.val_accuracy,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "        )\n",
    "\n",
    "        return step_out\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int) -> Mapping[str, Any]:\n",
    "        x, y = self.unwrap_batch(batch)\n",
    "\n",
    "        step_out = self.step(x, y)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\"loss/test\": step_out[\"loss\"].cpu().detach()},\n",
    "        )\n",
    "\n",
    "        self.test_accuracy(torch.softmax(step_out[\"logits\"], dim=-1), y)\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"acc/test\": self.test_accuracy,\n",
    "            },\n",
    "            on_epoch=True,\n",
    "        )\n",
    "\n",
    "        return step_out\n",
    "\n",
    "    def configure_optimizers(\n",
    "        self,\n",
    "    ) -> Union[Optimizer, Tuple[Sequence[Optimizer], Sequence[Any]]]:\n",
    "        \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
    "\n",
    "        Normally you'd need one. But in the case of GANs or similar you might have multiple.\n",
    "\n",
    "        Return:\n",
    "            Any of these 6 options.\n",
    "            - Single optimizer.\n",
    "            - List or Tuple - List of optimizers.\n",
    "            - Two lists - The first list has multiple optimizers, the second a list of LR schedulers (or lr_dict).\n",
    "            - Dictionary, with an 'optimizer' key, and (optionally) a 'lr_scheduler'\n",
    "              key whose value is a single LR scheduler or lr_dict.\n",
    "            - Tuple of dictionaries as described, with an optional 'frequency' key.\n",
    "            - None - Fit will run without any optimizer.\n",
    "        \"\"\"\n",
    "        return [torch.optim.Adam(self.parameters(), lr=1e-3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEGlFftWxzEJ"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_tFuXkvyFR_"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = MNIST(root=\".\", train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root=\".\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0I-cJ3rx1G_"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1000, num_workers=8)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2QBZxY8v3M7"
   },
   "source": [
    "## Train a bunch of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_OVpiqJHvjBU",
    "outputId": "ecbc91a5-2141-419c-cbc6-c8cf339fed02"
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model_a = MyLightningModule(MLP(num_classes), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "5H-M4n6Dw1aC",
    "outputId": "56cd1d79-c503-4aea-e51b-dcfe0b7b2256"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "trainer = Trainer(enable_progress_bar=True, enable_model_summary=False, max_epochs=50)\n",
    "\n",
    "trainer.fit(model_a, train_loader)\n",
    "\n",
    "trainer.test(model_a, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXo6520VxMVI"
   },
   "source": [
    "## Match the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujovajWkvef3"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class PermutationSpec(NamedTuple):\n",
    "    # maps permutation matrices to the layers they permute, expliciting the axis they act on\n",
    "    perm_to_layers_and_axes: dict\n",
    "\n",
    "    # maps layers to permutations: if a layer has k dimensions, it maps to a permutation matrix (or None) for each dimension\n",
    "    layer_and_axes_to_perm: dict\n",
    "\n",
    "\n",
    "class PermutationSpecBuilder:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def create_permutation_spec(self) -> list:\n",
    "        pass\n",
    "\n",
    "    def permutation_spec_from_axes_to_perm(self, axes_to_perm: dict) -> PermutationSpec:\n",
    "        perm_to_axes = defaultdict(list)\n",
    "\n",
    "        for wk, axis_perms in axes_to_perm.items():\n",
    "            for axis, perm in enumerate(axis_perms):\n",
    "                if perm is not None:\n",
    "                    perm_to_axes[perm].append((wk, axis))\n",
    "\n",
    "        return PermutationSpec(perm_to_layers_and_axes=dict(perm_to_axes), layer_and_axes_to_perm=axes_to_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoA_QxmKvZ5Y"
   },
   "outputs": [],
   "source": [
    "class MLPPermutationSpecBuilder(PermutationSpecBuilder):\n",
    "    def __init__(self, num_hidden_layers: int):\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "\n",
    "    def create_permutation_spec(self) -> PermutationSpec:\n",
    "        L = self.num_hidden_layers\n",
    "        assert L >= 1\n",
    "\n",
    "        axes_to_perm = {\n",
    "            \"layer0.weight\": (\"P_0\", None),\n",
    "            **{f\"layer{i}.weight\": (f\"P_{i}\", f\"P_{i-1}\") for i in range(1, L)},\n",
    "            **{f\"layer{i}.bias\": (f\"P_{i}\",) for i in range(L)},\n",
    "            f\"layer{L}.weight\": (None, f\"P_{L-1}\"),\n",
    "            f\"layer{L}.bias\": (None,),\n",
    "        }\n",
    "\n",
    "        return self.permutation_spec_from_axes_to_perm(axes_to_perm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XTu71N5FwVnb",
    "GCXtENV8xXJx",
    "fSmkCPy0xOc2",
    "0vM0UnnNwbGE",
    "K2QBZxY8v3M7"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
