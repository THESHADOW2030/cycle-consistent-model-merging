{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = '02321c49'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ccmm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/ccmm/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/root/miniconda3/envs/ccmm/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZNK3c107SymBool10guard_boolEPKcl'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "import os\n",
    "\n",
    "import omegaconf\n",
    "import pytorch_lightning\n",
    "from nn_core.common import PROJECT_ROOT\n",
    "import dataclasses\n",
    "from typing import List\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Callback\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import dataclasses\n",
    "from typing import Union\n",
    "import random\n",
    "from hydra.utils import instantiate\n",
    "from pydoc import locate\n",
    "from nn_core.serialization import load_model\n",
    "from typing import List\n",
    "from nn_core.callbacks import NNTemplateCore\n",
    "from nn_core.model_logging import NNLogger\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Callback\n",
    "import logging\n",
    "import json\n",
    "import re \n",
    "\n",
    "pylogger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 100 epochs \n",
    "\n",
    "path = f'../storage/cycle-consistent-model-merging/{run}/checkpoints/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from typing import Dict, List\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(version_base=None, config_path=str(\"../conf\"), job_name=\"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"mlp\", overrides=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nn': {'dataset': {'train': {'_target_': 'torchvision.datasets.MNIST', 'root': '${nn.data_path}', 'train': True, 'download': True, 'transform': '${nn.dataset.train_transform}'}, 'test': {'_target_': 'torchvision.datasets.MNIST', 'root': '${nn.data_path}', 'train': False, 'download': True, 'transform': '${nn.dataset.test_transform}'}, 'train_transform': {'_target_': 'torchvision.transforms.Compose', 'transforms': [{'_target_': 'torchvision.transforms.ToTensor'}, {'_target_': 'torchvision.transforms.Normalize', 'mean': [0.1307], 'std': [0.3081]}]}, 'test_transform': '${nn.dataset.train_transform}'}, 'data_path': '${oc.env:PROJECT_ROOT}/data', 'output_path': '${oc.env:PROJECT_ROOT}/output', 'dataset_name': 'MNIST', 'data': {'_target_': 'ccmm.data.datamodule.MyDataModule', 'dataset': '${nn.dataset}', 'gpus': '${train.trainer.gpus}', 'num_workers': {'train': 8, 'val': 4, 'test': 4}, 'batch_size': {'train': 512, 'val': 512, 'test': 512}}, 'module': {'_target_': 'ccmm.pl_modules.pl_module.MyLightningModule', 'model_name': 'MLP', 'model': {'_target_': 'ccmm.models.mlp.MLP', 'input': 784}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0}, 'lr_scheduler': {'_target_': 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts', 'T_0': 10, 'T_mult': 2, 'eta_min': 0, 'last_epoch': -1, 'verbose': False}}}, 'train': {'seed_index': 2, 'deterministic': False, 'trainer': {'fast_dev_run': False, 'gpus': 1, 'precision': 32, 'max_epochs': 100, 'max_steps': 10000, 'accumulate_grad_batches': 1, 'num_sanity_val_steps': 2, 'gradient_clip_val': 10.0, 'val_check_interval': 1.0, 'deterministic': '${train.deterministic}'}, 'restore': {'ckpt_or_run_path': None, 'mode': 'continue'}, 'monitor': {'metric': 'loss/train', 'mode': 'min'}, 'callbacks': [{'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'save_top_k': -1, 'verbose': False, 'monitor': '${train.monitor.metric}', 'mode': '${train.monitor.mode}'}, {'_target_': 'pytorch_lightning.callbacks.LearningRateMonitor', 'logging_interval': 'step', 'log_momentum': False}, {'_target_': 'pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar', 'refresh_rate': 20}], 'logging': {'upload': {'run_files': True, 'source': True}, 'logger': {'_target_': 'pytorch_lightning.loggers.WandbLogger', 'project': '${core.project_name}', 'entity': None, 'log_model': '${..upload.run_files}', 'mode': 'online', 'tags': '${core.tags}'}, 'wandb_watch': {'log': 'all', 'log_freq': 100}}}, 'core': {'project_name': 'cycle-consistent-model-merging', 'storage_dir': '${oc.env:PROJECT_ROOT}/storage', 'version': '0.0.1', 'tags': ['dev']}}\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_ckpt(model_path: str) -> pl.LightningModule:\n",
    "\n",
    "    model_class = locate(\"ccmm.pl_modules.pl_module.MyLightningModule\")\n",
    "    model = load_model(model_class, checkpoint_path=Path(model_path))\n",
    "    model.eval().cuda()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_sort_checkpoints(checkpoint_dir):\n",
    "    # Get all files in the directory\n",
    "    checkpoint_files = os.listdir(checkpoint_dir)\n",
    "\n",
    "    # Filter only .ckpt files\n",
    "    checkpoint_files = [file for file in checkpoint_files if file.endswith('.ckpt.zip')]\n",
    "\n",
    "    # Sort files based on epoch number\n",
    "    checkpoint_files.sort(key=lambda x: int(re.search(r'epoch=(\\d+)', x).group(1)))\n",
    "\n",
    "    \n",
    "    checkpoints = [load_model_ckpt(os.path.join(checkpoint_dir, file)) for file in checkpoint_files]\n",
    "    return checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/cycle-consistent-model-merging/src/ccmm/pl_modules/pl_module.py:142: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n"
     ]
    }
   ],
   "source": [
    "checkpoints = load_and_sort_checkpoints(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_by_epoch = checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "K = 10\n",
    "\n",
    "all_params = []\n",
    "for epoch_model in models_by_epoch[:K]:\n",
    "    params = epoch_model.state_dict()\n",
    "    # flatten and concatenate all the parameters in a single vector\n",
    "    params = torch.cat([p.flatten() for p in params.values()])\n",
    "    all_params.append(params)\n",
    "\n",
    "all_params = torch.stack(all_params)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1061130])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (K, num_params_per_model)\n",
    "all_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_differences = []\n",
    "for i in range(1, K):\n",
    "    all_differences.append(all_params[i] - all_params[i-1])\n",
    "\n",
    "all_differences = torch.stack(all_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1061130, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape (num_params_per_model, K-1)\n",
    "all_differences = all_differences.transpose(1, 0)\n",
    "all_differences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = torch.linalg.qr(all_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.linalg.solve(R.conj().t() @ R, -torch.ones_like(R[0]))\n",
    "gamma = d / d.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_weights = (all_params[:-1].t() * gamma).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m models_by_epoch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# reshape proj_weights into the original shape\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m proj_weights \u001b[38;5;241m=\u001b[39m \u001b[43mproj_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m([p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m models_by_epoch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[1;32m      8\u001b[0m proj_weights \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mreshape(s) \u001b[38;5;28;01mfor\u001b[39;00m p, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(proj_weights, shapes)]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# assign the weights to the model\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# copy model_by_epoch[0] to new_model\n",
    "import copy\n",
    "new_model = copy.deepcopy(models_by_epoch[0])\n",
    "# get the original shape of the parameter layers\n",
    "shapes = [p.shape for p in models_by_epoch[0].state_dict().values()]\n",
    "# reshape proj_weights into the original shape\n",
    "proj_weights = proj_weights.split([p.numel() for p in models_by_epoch[0].state_dict().values()])\n",
    "proj_weights = [p.reshape(s) for p, s in zip(proj_weights, shapes)]\n",
    "# assign the weights to the model\n",
    "for p, w in zip(new_model.state_dict().values(), proj_weights):\n",
    "    p.copy_(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performances of the model on the test set\n",
    "from ccmm.pl_modules.pl_module import MyLightningModule\n",
    "from ccmm.pl_modules.data_module import MyDataModule\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
